{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "from pprint import pprint\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import collections\n",
    "from functools import reduce\n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_dataset():\n",
    "    # 加载基于所有电影的标签\n",
    "    _tags = pd.read_csv(\"all-tags.csv\", usecols=range(1, 3)).dropna()\n",
    "    tags = _tags.groupby(\"movieId\").agg(list)\n",
    "    \n",
    "    # 加载电影列表数据\n",
    "    movies = pd.read_csv(\"movies.csv\", index_col=\"movieId\")\n",
    "    # 将电影的类别词分开\n",
    "    movies['genres'] = movies['genres'].apply(lambda x: x.split(\"|\"))\n",
    "    \n",
    "    # 为每部电影匹配对应的标签数据， 如果没有将会是NAN\n",
    "    movies_index = set(movies.index) & set(tags.index)\n",
    "    new_tags = tags.loc[list(movies_index)]\n",
    "    ret = movies.join(new_tags)\n",
    "    \n",
    "    # 构建电影数据集， 包含电影ID， 电影名称， 类别和标签四个字段\n",
    "    # 如果电影没有标签数据， 就替换为空列表\n",
    "    df = map(lambda x: (x[0], x[1], x[2], x[2]+x[3]) if x[3] is not np.nan else (x[0], x[1], x[2], []), ret.itertuples())\n",
    "    movies_dataset = pd.DataFrame(df, columns=['movieId', 'title', 'genres', 'tags'])\n",
    "    \n",
    "    movies_dataset.set_index(\"movieId\", inplace=True)\n",
    "    return movies_dataset\n",
    "\n",
    "def create_movie_profile(movie_dataset):\n",
    "    '''\n",
    "    使用tfidf，分析提取topn关键词\n",
    "    :param movie_dataset:\n",
    "    :return:\n",
    "    '''\n",
    "    dataset = movie_dataset[\"tags\"].values\n",
    "\n",
    "    # 根据数据集建立词袋，并统计词频，将所有词放入一个词典，使用索引进行获取\n",
    "    dct = Dictionary(dataset)\n",
    "    # 根据将每条数据，返回对应的词索引和词频\n",
    "    corpus = [dct.doc2bow(line) for line in dataset]\n",
    "    # 训练TF-IDF模型，即计算TF-IDF值\n",
    "    model = TfidfModel(corpus)\n",
    "\n",
    "    _movie_profile = []\n",
    "    for i, data in enumerate(movie_dataset.itertuples()):\n",
    "        mid = data[0]\n",
    "        title = data[1]\n",
    "        genres = data[2]\n",
    "        vector = model[corpus[i]]\n",
    "        movie_tags = sorted(vector, key=lambda x: x[1], reverse=True)[:30]\n",
    "        topN_tags_weights = dict(map(lambda x: (dct[x[0]], x[1]), movie_tags))\n",
    "        # 将类别词的添加进去，并设置权重值为1.0\n",
    "        for g in genres:\n",
    "            topN_tags_weights[g] = 1.0\n",
    "        topN_tags = [i[0] for i in topN_tags_weights.items()]\n",
    "        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))\n",
    "\n",
    "    movie_profile = pd.DataFrame(_movie_profile, columns=[\"movieId\", \"title\", \"profile\", \"weights\"])\n",
    "    movie_profile.set_index(\"movieId\", inplace=True)\n",
    "    return movie_profile\n",
    "\n",
    "def create_inverted_table(movie_profile):\n",
    "    inverted_table = {}\n",
    "    for mid, weights in movie_profile['weights'].items():\n",
    "        for tag, weight in weights.items():\n",
    "            # 到inverted_table dict 用tag作为key去取值， 如果取不到就返回[]\n",
    "            _ = inverted_table.get(tag, [])\n",
    "            _.append((mid, weight))\n",
    "            inverted_table.setdefault(tag, _)\n",
    "    return inverted_table\n",
    "\n",
    "def get_watch_record():\n",
    "    watch_record = pd.read_csv(\"ratings.csv\", usecols=range(2), dtype={\"userId\":np.int32, \"movieId\": np.int32})\n",
    "    watch_record = watch_record.groupby(\"userId\").agg(list)\n",
    "    return watch_record\n",
    "\n",
    "def create_user_profile(watch_record):\n",
    "    user_profile = {}\n",
    "    for uid, mids in watch_record.itertuples():\n",
    "        record_movie_profile = movie_profile.loc[list(mids)]  # 这里把当前用户看过的电影从movie_profile中找出来\n",
    "        # print(record_movie_profile)\n",
    "        # 下面需要把这些电影的标签都合并到一块， 然后统计出现的次数\n",
    "        counter = collections.Counter(reduce(lambda x, y: list(x) + list(y), record_movie_profile['profile'].values))\n",
    "        \n",
    "        # 兴趣词\n",
    "        interest_words = counter.most_common(50)\n",
    "        maxcount = interest_words[0][1]\n",
    "        interest_words = [(w, round(c/maxcount, 4)) for w, c, in interest_words]  # 这里归一化一下\n",
    "        user_profile[uid] = interest_words\n",
    "    return user_profile\n",
    "\n",
    "def update_all_recommends():\n",
    "    movie_dataset = get_movie_dataset()\n",
    "    movie_profile = create_movie_profile(movie_dataset)\n",
    "    inverted_table = create_inverted_table(movie_profile)\n",
    "    watch_record = get_watch_record()\n",
    "    user_profile = create_user_profile(watch_record)\n",
    "    \n",
    "    if not os.path.exists('recommends.json'):\n",
    "        with open('recommends.json', 'w') as f:\n",
    "            json.dump({}, f)\n",
    "    \n",
    "    with open('recommends.json', 'r+') as f:\n",
    "        recommends_data = {}\n",
    "        \n",
    "        for uid, interest_words in user_profile.items():\n",
    "            result_table = {}   # 电影id: [0.2, 0.5]\n",
    "            for interest_word, interest_weight in interest_words:\n",
    "                related_movies = inverted_table[interest_word]\n",
    "                for mid, relate_weight in related_movies:\n",
    "                    _ = result_table.get(mid, [])\n",
    "                    _.append(interest_weight)    #只考虑用户的兴趣程度\n",
    "                    # _.append(related_weight)   # 只考虑兴趣词与电影的关联程度\n",
    "                    # _.append(interest_weight * related_weight)     # 二者都考虑\n",
    "                    result_table.setdefault(mid, _)\n",
    "            rs_result = map(lambda x: (x[0], movie_dataset.loc[x[0], 'title'], sum(x[1])), result_table.items()) \n",
    "            # 过滤掉已经观看过的电影\n",
    "            rs_result = filter(lambda x: x[0] not in watch_record.loc[uid, 'movieId'], rs_result)\n",
    "            rs_result = sorted(rs_result, key=lambda x: x[2], reverse=True)[:100]\n",
    "            \n",
    "            # 更新或添加到 recommends_data 字典中\n",
    "            recommends_data[str(uid)] = rs_result\n",
    "        \n",
    "        # 将更新后的数据写入到 recommends.json 文件中\n",
    "        f.seek(0)\n",
    "        json.dump(recommends_data, f, indent=4)\n",
    "\n",
    "def update_one_recommend(user_id):\n",
    "    movie_dataset = get_movie_dataset()\n",
    "    movie_profile = create_movie_profile(movie_dataset)\n",
    "    inverted_table = create_inverted_table(movie_profile)\n",
    "    watch_record = get_watch_record()\n",
    "    user_profile = create_user_profile(watch_record)\n",
    "    \n",
    "    if not os.path.exists('recommends.json'):\n",
    "        with open('recommends.json', 'w') as f:\n",
    "            json.dump({}, f)\n",
    "    \n",
    "    with open('recommends.json', 'r+') as f:\n",
    "        recommends_data = json.load(f)\n",
    "        # pprint(recommends_data)\n",
    "        \n",
    "        for uid, interest_words in user_profile.items():\n",
    "            if user_id != uid:\n",
    "                continue\n",
    "            result_table = {}   # 电影id: [0.2, 0.5]\n",
    "            for interest_word, interest_weight in interest_words:\n",
    "                related_movies = inverted_table[interest_word]\n",
    "                for mid, relate_weight in related_movies:\n",
    "                    _ = result_table.get(mid, [])\n",
    "                    _.append(interest_weight)    #只考虑用户的兴趣程度\n",
    "                    # _.append(related_weight)   # 只考虑兴趣词与电影的关联程度\n",
    "                    # _.append(interest_weight * related_weight)     # 二者都考虑\n",
    "                    result_table.setdefault(mid, _)\n",
    "            # print(result_table)\n",
    "            rs_result = map(lambda x: (x[0], movie_dataset.loc[x[0], 'title'], sum(x[1])), result_table.items()) \n",
    "            # 过滤掉已经观看过的电影\n",
    "            rs_result = filter(lambda x: x[0] not in watch_record.loc[uid, 'movieId'], rs_result)\n",
    "            rs_result = sorted(rs_result, key=lambda x: x[2], reverse=True)[:100]\n",
    "            recommends_data[str(uid)] = rs_result\n",
    "            \n",
    "            # 将更新后的数据写入到 recommends.json 文件中\n",
    "            f.seek(0)\n",
    "            json.dump(recommends_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_all_recommends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_one_recommend(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dataset = get_movie_dataset()\n",
    "movie_profile = create_movie_profile(movie_dataset)\n",
    "inverted_table = create_inverted_table(movie_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_record = pd.read_csv(\"ratings.csv\", usecols=range(2), dtype={\"userId\":np.int32, \"movieId\": np.int32})\n",
    "watch_record = watch_record.groupby(\"userId\").agg(list)\n",
    "# print(watch_record)\n",
    "\n",
    "user_profile = {}\n",
    "for uid, mids in watch_record.itertuples():\n",
    "    record_movie_profile = movie_profile.loc[list(mids)]  # 这里把当前用户看过的电影从movie_profile中找出来\n",
    "    # print(record_movie_profile)\n",
    "    # 下面需要把这些电影的标签都合并到一块， 然后统计出现的次数\n",
    "    counter = collections.Counter(reduce(lambda x, y: list(x) + list(y), record_movie_profile['profile'].values))\n",
    "    \n",
    "    # 兴趣词\n",
    "    interest_words = counter.most_common(50)\n",
    "    maxcount = interest_words[0][1]\n",
    "    interest_words = [(w, round(c/maxcount, 4)) for w, c, in interest_words]  # 这里归一化一下\n",
    "    user_profile[uid] = interest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for uid, interest_words in user_profile.items():\n",
    "    result_table = {}   # 电影id: [0.2, 0.5]\n",
    "    for interest_word, interest_weight in interest_words:\n",
    "        related_movies = inverted_table[interest_word]\n",
    "        for mid, relate_weight in related_movies:\n",
    "            _ = result_table.get(mid, [])\n",
    "            _.append(interest_weight)    #只考虑用户的兴趣程度\n",
    "            # _.append(related_weight)   # 只考虑兴趣词与电影的关联程度\n",
    "            # _.append(interest_weight * related_weight)     # 二者都考虑\n",
    "            result_table.setdefault(mid, _)\n",
    "    # print(result_table)\n",
    "    rs_result = map(lambda x: (x[0], movie_dataset.loc[x[0], 'title'], sum(x[1])), result_table.items()) \n",
    "    # 过滤掉已经观看过的电影\n",
    "    rs_result = filter(lambda x: x[0] not in watch_record.loc[uid, 'movieId'], rs_result)\n",
    "    rs_result = sorted(rs_result, key=lambda x: x[2], reverse=True)[:100]\n",
    "    print(uid)\n",
    "    pprint(rs_result)\n",
    "    # recommend_list.update({uid: rs_result})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
